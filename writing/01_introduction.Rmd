Developmental psychology focuses on how psychological constructs change with age. Throughout the years, many theories have been proposed to characterize and explain how and why developmental changes happen [e.g., @piaget1971theory; @bronfenbrenner1977toward; @carey2009origin; @thelen2007dynamic; @elman1996rethinking; @flavell1994cognitive]. Among these theories, one common assumption is that skills refines with age, an assumption we call the "positive change assumption." Often, researchers treat age as a predictor in linear regression models, and therefore implicitly assume that their construct of interest -- or at least the measure they use to operationalize it -- has a linear relationship with age [@lindenberger1998complex]. 

One common approach to evaluating the functional form of age-related changes is through observational studies with longitudinal measurement. When tracked longitudinally, measurements of psychological constructs often reveal age trajectories that violate the linearity assumption. For instance, a longitudinal study that followed the development of executive function (EF) from 3 to 5 years-old using a battery of EF tasks showed that EF development follows a non-linear trajectory over age [@johansson2016individual]. Or for another example, vocabulary in early childhood -- as measured by MacArthur-Bates Communicative Development Inventories -- also follows an exponential trend rather than the linear trend [@frank2021variability]. Indeed many domains with established measurements, longitudinal research has been used to characterize the functional form of development [@adolph2008shape; @mcardle2009modeling; @cole2020development; @karlberg1987analysis; @tilling2014modelling]. 

Due to their resource-intensive nature, longitudinal methods are more rarely applied when measuring specific experimental effects, however. Many important findings in early language and cognitive development are primarily attested in cross-sectional experimental studies. For example, in the language learning domain, many studies have targeted specific mechanisms proposed to underlie how infants acquire specific facets of language. Constructs such as mutual exclusivity [@markman1988children], statistical learning [@saffran1996statistical], syntactic bootstrapping [@naigles1990children], and so on, are all attested through decades of experimental evidence acquired via cross-sectional studies. 

These findings provide critical evidence about the causal mechanisms underlying developmental growth, but it is challenging to make inferences about developmental changes in the mechanisms themselves. For example, statistical learning is hypothesized to be a mechanism underlying language learning and other aspects of cognitive and perceptual development [@saffran2018]. But does the rate of statistical learning -- or other such foundational mechanisms -- change across age? It is often challenging to make inferences about such changes from individual experimental papers.

First of all, the measurements properties of many experimental paradigms are rarely examined [@byers2022six]. When adapting an experimental design to test on a different age group, researchers often make adjustments based on intuitions or trial and error. For instance, an experimental paradigm that measures reaching might be too challenging for younger infants, so the researchers instead might measure looking time. While such adaptations of measurement are sometimes useful for revealing an effect in younger ages, they also alter the psychometric properties of the experimental paradigm, changing the relationship between the latent construct and the observed effect. Consequently, it can be difficult to compare infants' underlying abilities at one age measured using one paradigm with their abilities at an older age measured using a different pareadigm. 

Even when we assume the same psychometric properties of the experimental paradigm across age groups, many effects are not measured in samples with sufficient size and age variation to test the assumption of positive change or the assumption of linear developmental growth in a single study [cf. @frank2017collaborative]. In an ideal world, these experiments would be conducted longitudinally on a large, diverse sample [@kidd2022diverse]. This goal is difficult to achieve in practice due to time and resource constraints. As a result, the functional form of age-related change in many constructs remains poorly understood. 

To address this issue, we turn to meta-analysis. Meta-analysis is a statistical method to aggregate evidence across studies. This approach has been widely adopted in many disciplines and subfields, including developmental psychology [@hyde1984large; @letourneau2013socioeconomic; @doebel2015meta]. Compared with studying developmental change using single studies, meta-analysis has several advantages. First, it allows us to examine the robustness of phenomena: By combining results from multiple studies, meta-analysis enhances the statistical power to detect effects that might be too small to identify in individual studies. Second, meta-analysis provides a framework for assessing the consistency of research findings across different contexts [@borenstein2021introduction; @egger1997meta]. Finally, pooling across developmental studies with different cross-sectional samples may yield sufficient variation to explore the functional form of age-related change with greater precision than individual studies.

In the current work, we aim to leverage meta-analysis to examine the shape of the developmental trajectory in key constructs in infant language and cognitive development. We use existing meta-analyses from Metalab (https://langcog.github.io/metalab/), a platform that hosts community-augmented meta-analyses. Metalab was established to provide a publicly available database of dynamically-updated meta-analyses [@bergmann2018promoting]. Researchers can deposit their data on the platform, and they can also use data from Metalab for their own analyses [@cao2023synthesis; @lewis2016quantitative; @cao2022quantifying]. To date, Metalab contains 2967 effect sizes from 32 different meta-analysis and 48,529 unique participants, spanning different areas of developmental psychology ^[The dataset used in the current paper can be found in our github repository: [](https://github.com/anjiecao/metalabr_exp)]. This resource allows us to examine the suitability of meta-analysis as a tool to characterize developmental trajectories for a variety of phenomena -- and if suitable, to provide insight into how these constructs develop across early childhood. 

We acknowledge at the outset that meta-analysis has significant limitations. A first issue in interpreting meta-analysis is heterogeneity in study participants, interventions, outcomes, and methodologies. This diversity, when it originates from non-theoretically relevant variables, can make it challenging to aggregate results meaningfully, because differences between studies may reflect true variation in effects rather than a singular underlying effect size [@fletcher2007heterogeneity;@higgins2002quantifying; @thompson1999explaining; @huedo2006assessing]. Critically, understanding the source of heterogeneity often requires detailed coding of potential moderators; this process is frequently hampered by the inadequate reporting standards prevalent in psychological literature, which often leaves essential information for coding these moderators absent [@publications2008reporting;@nicholson2017attrition]. This process is also limited by the amount of studies available. If a moderator is only present in a few studies, then the lack of power would prohibit the testing of this moderator's influence. 

Second, the quality of a meta-analysis is necessarily constrained by the quality of the existing studies [@simonsohn2022above; @eysenck1978exercise]. Effect sizes themselves can not inform us about the psychometric properties of the measurements, and the strengths of the effect from a particular study does not map directly onto the magnitude of the latent construct for that sample. Further, if the studies being aggregated are flawed, the conclusions drawn from the meta-analysis will also be questionable. In sum, whether meta-analysis can provide insights into the nature of age-related change is dependent upon the quality and quantity of the existing literature.

This paper is organized as follows. In the first section, we provide an overview of the estimated shape of age-related change across the datasets in Metalab. For each dataset, we compared the fit of models using four different functional forms for age-related change: linear, logarithmic, quadratic, and constant. To preview our findings, we found that most datasets showed relatively constant effect sizes across age. For the datasets that showed a significant age effect, none supported the linearity assumption. In the second section, we tested four hypotheses about why many of the current meta-analyses might not show age-related change: 

1. Age-related selection bias against younger infants. Perhaps there is more severe publication bias in studies testing younger infants, resulting in more inflated effect sizes in younger infants; 
2. Methodological adaptation for older infants. Perhaps experimenters make their experiments more challenging for older infants, which results in diminished effect sizes in older infants.
3. Change for some conditions but not others. Perhaps age effects are easier to detect in the subset of experimental conditions that show the strongest effect sizes.
4. Positive growth only after infancy. Perhaps age-related changes are easier to detect in older children or emerge after early infancy due to non-linearities in development. 

None of these four explanations provided an explanation for the lack of age-related change in most of the meta-analyses we examined. 


```{r results = "asis"}
table_1 <- readRDS(here("writing/display_items/table_1.Rds"))
#table_1 %>% papaja::apa_table(landscape = TRUE, longtable = TRUE)
```

\begin{lltable}

\begin{longtable}{llllll}\noalign{\getlongtablewidth\global\LTcapwidth=\longtablewidth}
\caption{\label{tab:unnamed-chunk-12} This table summarizes the number of effect sizes (ES) and the number of participants included in each dataset. The ES estimates represent the aggregated effect sizes and their 95\% confidence intervals. The $I^2$ measures the heterogneity of each dataset. The paper source column indicates the published record associated with each dataset.}\\
\toprule
Dataset & \multicolumn{1}{c}{N ES} & \multicolumn{1}{c}{N Subject} & \multicolumn{1}{c}{MA ES} & \multicolumn{1}{c}{$I^2$} & \multicolumn{1}{c}{Source paper / Data Curator}\\
\midrule
\endfirsthead
\caption*{\normalfont{Table \ref{tab:unnamed-chunk-12} continued}}\\
\toprule
Dataset & \multicolumn{1}{c}{N ES} & \multicolumn{1}{c}{N Subject} & \multicolumn{1}{c}{MA ES} & \multicolumn{1}{c}{$I^2$} & \multicolumn{1}{c}{Source paper / Data Curator}\\
\midrule
\endhead
Abstract rule learning & 95 & 1123 & 0.22 [0.07, 0.37] & 0.80 & Rabagliati et al., (2018)\\
Audio-visual congruence & 92 & 4132 & 0.33 [0.19, 0.47] & 0.89 & Cox et al., (2022)\\
Categorization bias & 80 & 594 & 0.16 [-0.66, 0.99] & 0.96 & Molly Lewis\\
Cross-situational word learning & 48 & 2241 & 0.67 [0.5, 0.84] & 0.90 & Rodrigo Dal Ben\\
Familiar word recognition & 34 & 586 & 0.54 [0.38, 0.69] & 0.55 & Carbajal et al., (2021)\\
Gaze following (combined) & 81 & 1407 & 0.81 [0.61, 1.01] & 0.90 & Frank et al., (2016)\\
Infant directed speech preference & 100 & 1267 & 0.37 [0.25, 0.49] & 0.71 & Zettersten et al., (2023)\\
Label advantage in concept learning & 100 & 1644 & 0.36 [0.23, 0.48] & 0.73 & Molly Lewis\\
Language discrimination & 104 & 1479 & -0.26 [-0.4, -0.11] & 0.77 & Gasparini et al., (2021)\\
Language preference & 49 & 641 & 0.11 [-0.06, 0.28] & 0.93 & Gasparini et al., (2021)\\
Mispronunciation sensitivity & 249 & 2122 & 0.45 [0.24, 0.66] & 0.94 & Von Holzen \& Bergmann (2021)\\
Mutual exclusivity & 131 & 2222 & 1.27 [0.99, 1.56] & 0.95 & Lewis et al. (2020)\\
Natural speech preference & 55 & 786 & 0.44 [0.23, 0.65] & 0.83 & Issard et al., (2023)\\
Neonatal Imitation & 336 & 2455 & 0.68 [0.4, 0.97] & 0.94 & Davis et al. (2021)\\
Online word recognition & 14 & 330 & 1.37 [0.78, 1.96] & 0.95 & Frank et al., (2016)\\
Prosocial agents & 61 & 1244 & 0.4 [0.29, 0.52] & 0.20 & Margoni \& Surian (2018)\\
Simple arithmetic competences & 14 & 369 & 0.25 [0.04, 0.46] & 0.54 & Christodoulou et al., (2017)\\
Sound symbolism & 44 & 425 & 0.16 [-0.01, 0.33] & 0.69 & Fort et al. (2018)\\
Statistical sound category learning & 20 & 591 & 0.29 [0.01, 0.57] & 0.58 & Cristia (2018)\\
Statistical word segmentation & 103 & 804 & -0.08 [-0.18, 0.02] & 0.83 & Black \& Bergmann (2017)\\
Switch task & 143 & 2764 & -0.16 [-0.25, -0.06] & 0.78 & Tsui et al., (2019)\\
Syntactic bootstrapping & 60 & 832 & 0.24 [0.03, 0.44] & 0.72 & Cao \& Lewis (2022)\\
Vowel discrimination (native) & 143 & 2418 & 0.59 [0.43, 0.75] & 0.78 & Tsuji \& Cristia (2014)\\
Vowel discrimination (non-native) & 49 & 600 & 0.65 [0.2, 1.1] & 0.92 & Tsuji \& Cristia (2014)\\
Word segmentation (combined) & 315 & 2910 & 0.2 [0.14, 0.26] & 0.78 & Bergmann \& Cristia (2016)\\
\bottomrule
\end{longtable}

\end{lltable}


 
```{r}
table_2 <- readRDS(here("writing/display_items/table_2.Rds"))
#table_2 %>% papaja::apa_table()
```
 
\begin{table*}[hbt]
\ifnextchar[{\eatarg}{}
[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:unnamed-chunk-10} This table summarizes the values of $\Delta$ of corrected Akaike Information Criterion (AICc) for the age model with different functional forms: Constant, Linear, Logarithmic, and Quadratic. The values were calculated from subtracting the minimum AICc from the AICc of each model. They were rounded to two decimals. Zeros represent the models with the best fit. The bold values indicate the best fitting model. Asterisks indicate that there is a significantly better fit compared to other functional forms for that dataset.}

\begin{tabular}{lllll}
\toprule
Dataset & \multicolumn{1}{c}{Const} & \multicolumn{1}{c}{Linear} & \multicolumn{1}{c}{Log} & \multicolumn{1}{c}{Quadratic}\\
\midrule
Cross-situational word learning & \bf{0.00} & 2.44 & 2.29 & 2.55\\
Language discrimination & \bf{0.00} & 1.32 & 0.91 & 1.59\\
Prosocial agents & \bf{0.00} & 2.08 & 1.87 & 2.15\\
Simple arithmetic competences & \bf{0.00*} & 6.65* & 6.74* & 6.55*\\
Statistical word segmentation & \bf{0.00} & 1.34 & 1.51 & 1.12\\
Switch task & \bf{0.00} & 1.12 & 1.15 & 1.06\\
Syntactic bootstrapping & \bf{0.00} & 0.71 & 0.56 & 0.88\\
Vowel discrimination (native) & \bf{0.00} & 1.34 & 0.99 & 1.63\\
Vowel discrimination (non-native) & \bf{0.00} & 1.56 & 1.67 & 1.46\\
Word segmentation (combined) & \bf{0.00} & 1.28 & 1.05 & 1.61\\
Infant directed speech preference & \bf{0.00} & 1.57 & 1.47 & 1.53\\
Mispronunciation sensitivity & 1.89 & \bf{0.00} & 0.05 & 0.19\\
Online word recognition & 2.22 & \bf{0.00} & 0.23 & 0.15\\
Sound symbolism & 3.91 & \bf{0.00} & 0.61 & 0.09\\
Audio-visual congruence & 5.90* & 6.70* & \bf{0.00*} & 7.44*\\
Label advantage in concept learning & 2.37 & 0.95 & \bf{0.00} & 1.63\\
Mutual exclusivity & 9.80* & 0.58 & \bf{0.00*} & 1.38\\
Neonatal Imitation & 2.25 & 0.36 & \bf{0.00} & 1.06\\
Abstract rule learning & 0.44 & 0.32 & 0.86 & \bf{0.00}\\
Categorization bias & 8.46* & 0.62 & 1.36 & \bf{0.00*}\\
Familiar word recognition & 1.68 & 0.28 & 1.15 & \bf{0.00}\\
Gaze following (combined) & 43.73* & 2.07 & 10.41* & \bf{0.00*}\\
Language preference & 2.50 & 2.36 & 4.12 & \bf{0.00}\\
Natural speech preference & 0.86 & 0.43 & 1.04 & \bf{0.00}\\
Statistical sound category learning & 3.44 & 1.04 & 3.01 & \bf{0.00}\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table*}
\efloatseparator
