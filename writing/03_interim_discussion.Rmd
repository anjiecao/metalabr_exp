
# Understanding the lack of developmental change in meta-analytic data

Here we consider four explanations for the lack of age-related change in most of the meta-analyses we examined. First, meta-analyses are susceptible to publication bias [@thornton2000publication; @francis2012publication; @ferguson2012vast; @ferguson2012publication]. And the bias could be related to the characteristics of the study, such as the inclusion of younger participants [@coburn2015publication]. Consequently, studies with younger participants may have effect sizes that were more inflated, compared to the studies with older participants. The selectivity of publication bias would thus obscure the possible developmental changes in the dataset.

```{r}
method_adaptation <- d %>% filter(ds_clean == "Language discrimination and preference (discrimination)") %>% group_by(behavioral_measure) %>% summarise(mean_age = mean(mean_age_months), sd_age = sd(mean_age_months)) %>% mutate_if(is.numeric, round, 2)

#method_adaptation
```

Second, researchers may change methods as infants expand their behavioral repertoire. For example, the high-amplitude sucking paradigm is most likely to be deployed on very young infants, whereas the looking paradigm is most likely to be used on older infants. We did see some evidence for method adaptation in some datasets. For example, in *Language discrimination*, the average age for studies using a sucking paradigm was `r filter(method_adaptation, behavioral_measure == "sucking")$mean_age` months (SD = `r filter(method_adaptation, behavioral_measure == "sucking")$sd_age`), but `r filter(method_adaptation, behavioral_measure == "looking")$mean_age` months (SD = `r filter(method_adaptation, behavioral_measure == "looking")$sd_age`) for studies using looking time paradigm.  This age-related change in research paradigms could lead to a case of Simpsonâ€™s paradox: the age-related trend within a single method might be lost when multiple methods are combined [@simpson1951interpretation; @kievit2013simpson].

```{r}
paper_info <- read_csv(here("data/rework/ma_paper_supplement.csv")) %>% 
  group_by(`With paper`) %>% 
  count()
n_has_paper <- paper_info %>% filter(`With paper` == "Yes") %>% pull(n)

better_half_info <- read_csv(here("data/rework/ma_paper_supplement.csv")) %>% 
  group_by(better_half_identified) %>% 
  count()

n_identify_better_half <- better_half_info %>% 
  filter(better_half_identified != "no", better_half_identified != "no (some by researcher variation)", !is.na(better_half_identified)) %>% 
  ungroup() %>% 
  count() %>% 
  pull(n)
```


Third, other methodological factors unrelated to age could also contribute to the lack of developmental effects. `r n_has_paper` of the 25 datasets included in the current analyses has a manuscript associated. Among the manuscripts, `r n_identify_better_half` identified that the meta-analytic effects were only robust in a subset of the studies. Some of the subsets were identified by certain methodological characters [e.g. in *Syntactic Bootstrapping*, the effect was only present in studies with transitive conditions, @cao2022quantifying], and other subsets were identified by participants characteristics [e.g. in *Familiar word recognition*, the effect was stronger in infants whose primary language exposure was from Romance languages, @carbajal2021meta]. Perhaps the apparent lack of developmental effects in the current analysis could be attributed to a complex interaction between methodological factors and participant characteristics, rather than a true absence of developmental changes.

Fourth, developmental change in infancy and early childhood might be distinct from one another. @bergelson2020comprehension has speculated that word comprehension in the looking-while-listening paradigm only shows significant developmental changes after 12 months of age, with infants younger than 12 months showing mostly flat developmental trajectories in this task. This contrast could be attributed to the fact that older infants are not only more experienced compared to younger infants, but also better learners who can more effectively take advantage of the input they receive. Could this pattern generalize to other tasks and domains? There is much evidence suggesting that developmental changes occurring in one domain would have cumulative, cascading effects on changes in other domains [@bornstein2018stability; @oakes2019developmental; @ahmed2021preschool]. The outcome of such developmental cascades might not be measurable in the experimental tasks included in the meta-analyses until infants are above 12 months of age. 

We investigate each of these explanations in turn, assessing empirical support in our data. We summarise the results of these analyses in Table 3; in brief, no explanation provided traction for more than a small number of datasets. 

```{r}
library(kableExtra)
library(gt)
table_3_df <- readRDS(here("writing/display_items/table_3.Rds"))

kable(table_3_df,
      format = "latex",
      longtable=TRUE,
      booktabs = TRUE,
      align = c("l"),
      col.names = c("","","Weight Function","Egger's Test", "", "", "")) %>%
  kable_styling("striped", full_width = F,
                position = "left", font_size = 10) %>% 
 # add_header_above(c("Dataset" = 1, "Linear Growth" = 1, "Publication Bias" = 2, 
 #                  "Methods Adaptation" = 1, "Theoretical Constraints" = 1, "Late emergence of growth"= 1))  %>% 
  add_header_above(c("Dataset" = 1, "Linear Growth" = 1, "Hypothesis 1" = 2, 
                   "Hypothesis 2" = 1, "Hypothesis 3" = 1, "Hypothesis 4"= 1))  %>% 
  landscape()
   
```




```{r fig.width=8, fig.height=8}
fig3 <- readRDS(here("writing/display_items/fig_3.Rds"))
fig3
```

