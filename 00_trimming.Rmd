---
title: "00_trimming.Rmd"
author: "anjie"
date: "`r Sys.Date()`"
output: html_document
---

GETTING RAW DATASET
```{r}
metalab_data %>% 
  distinct(dataset)

write_csv(metalab_data, here("data/metalab_data_july2023.csv"))
```



```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(janitor)
library(metalabr)
library(tidyboot)
library(ggthemes)

# metadata <- get_metalab_metadata()
# metalab_data <- get_metalab_data(metadata)
# write_csv(metalab_data, here("data/metalab_data.csv"))

metalab_data <- read_csv(here("data/metalab_data_july2023.csv"))

ids_data <- read_csv(here("data/rework/ids_clean.csv")) %>% 
  mutate(ds_clean = "Infant directed speech preference")

#@TODO: ADD NEW PROSOCIAL AGENTS
#https://docs.google.com/spreadsheets/d/1j2Af5jyMjqRC6FBQnqGeTPVJ5nacDVf2cu9a9D3Se4o/edit?pli=1#gid=1269834261
```



# metalab_data trimming procedure 

decision process for cogsci documented here: https://docs.google.com/spreadsheets/d/1_cPEL6Zek6UiyzxzJdBzkzDbor2lrrriDbdyimnWNtQ/edit#gid=23086810

```{r}
metalab_data %>% distinct(dataset)
```


## 1. Replace dataset and/or get rid of dataset

```{r}
trimmed_data <- metalab_data %>% 
  filter(!dataset %in% c(# dataset to be replaced 
                         "Infant directed speech preference", 
                         
                         # dataset to be excluded 
                         "Phonotactic learning", 
                         "Pointing and vocabulary (concurrent)", 
                         "Pointing and vocabulary (longitudinal)",
                         "Video deficit", 
                         "Word segmentation (neuro)", 
                         "Symbolic play	",
                         
                         # dataset to be modified 
                         "Statistical sound category learning", 
                         "Gaze following (live)",
                         "Gaze following (video)",
                         "Function word segmentation", 
                         "Word segmentation (behavioral)"
                         
                         )) %>% 
  mutate(ds_clean = dataset) %>% 
  bind_rows(
    ids_data %>% mutate(expt_num = as.numeric(expt_num)), #IDS replacement 

    # modifying statistical sound category learning 
    metalab_data %>% 
    filter(dataset == "Statistical sound category learning", exposure_phase == "habituation") %>% 
    mutate(ds_clean = "Statistical sound category learning (habituation)"), 
    
    #combining gaze following 
    metalab_data %>% 
      filter(dataset %in% c("Gaze following (live)","Gaze following (video)")) %>% 
      mutate(ds_clean = "Gaze following (combined)"),
    
    #combining function word segmentation 
    metalab_data %>% 
      filter(dataset %in% c("Function word segmentation", "Word segmentation (behavioral)")) %>% 
      mutate(ds_clean = "Word Segmentation (combined)")
    
  )

```




## 2. import method recode 

```{r}
m_recode <- read_csv(here("data/rework/ds_method_recode.csv"))


trimmed_data <- m_recode %>% 
  select(-note) %>% 
  left_join(trimmed_data, by = c("ds_clean", "response_mode", "method", "dependent_measure"))
  
```

## 3. import infant recode 

```{r}
it_recode <- read_csv(here("data/rework/ds_infant_type_recode.csv"))


trimmed_data <- it_recode %>% 
  select(-long_cite) %>% 
  left_join(trimmed_data, by = c("ds_clean", "native_lang", "infant_type")) %>% 
  rename(infant_type_clincal =  `infant_type_clinical (typical vs nt (preterm / delayed / developmental disorder)`)
```

## 4. prune infant recode (little variation)

- currently preserve the non-monolingual kids because the impact of bilingualism might be different for cog dev dataset than for lang dev dataset 

```{r}
trimmed_data <- trimmed_data %>% 
  filter(infant_type_clincal == "typical")
```


## 5. check consistencies in data 


### stimuli naturalness 



### age 

```{r}
missing_age_data <- trimmed_data %>% 
  filter(is.na(mean_age_months)) %>% 
  mutate(mean_age_months = mean_age_1 / 30.4)

trimmed_data <- trimmed_data %>% 
  filter(!is.na(mean_age_months)) %>% 
  bind_rows(missing_age_data) %>% 
  arrange(ds_clean)

```



### d_calc & d_var vs d_cal_var 

```{r}
missing_d_calc_data <- trimmed_data %>% 
  filter(is.na(d_calc)) %>% 
  mutate(d_calc = d, 
         d_var_calc = d_var)

trimmed_data <- trimmed_data %>% 
  filter(!is.na(d_calc)) %>% 
  bind_rows(missing_d_calc_data) %>% 
  filter(!(is.na(d_calc) | is.na(d_var_calc))) %>% 
  select(-d, -d_var)
  
```

### random effect structure relevant information 

random = ~ 1 | short_cite/same_infant/unique_row

```{r}
trimmed_data %>% 
  filter(is.na(short_cite))
```

```{r}
missing_same_infant <- trimmed_data %>% 
  filter(is.na(same_infant)) 

trimmed_data <- trimmed_data %>% 
  filter(!is.na(same_infant)) %>% 
  bind_rows(read_csv(here("data/rework/fix_res_same_infant.csv")) %>% mutate(same_infant = as.character(same_infant))) 
```

```{r}
missing_unique_row <- trimmed_data %>% 
  filter(is.na(unique_row)) %>% 
  group_by(ds_clean) %>% 
  mutate(unique_row = row_number()) %>% 
  ungroup()

trimmed_data <- trimmed_data %>% 
  filter(!is.na(unique_row)) %>% 
  bind_rows(missing_unique_row)


```


## 6. Clean up messy columns 

### Throw out columns just not gonna be used anymore

random = ~ 1 | short_cite/same_infant/unique_row

```{r}
pruned_data <- trimmed_data %>% 
  select(
    # universally unhelpful information 
    -`...12`, -coder, -group_name_1, -group_name_2, -stimuli_link, -data_link, 
    -sampa_comments, -g_calc, -g_var_calc, -r_calc, -r_var_calc, -z_calc, -z_var_calc, -log_odds_calc, -log_odds_var_calc, 
    -es_method, -mean_age, -same_infant_calc, -doi, -`2nd coder`, -`Coder 1 Comments`, -`Coder 1 Comments`
  ) 


# check if any column has 0 information 
pruned_data <- pruned_data %>% 
  select(!any_of(pruned_data %>% keep(~all(is.na(.x))) %>% names))
```







## 7. fix issue wrt the author exploration 

```{r}


pa_clean <- pruned_data %>% 
  filter(ds_clean == "Prosocial Agents") %>% 
  mutate(by_major_author = ifelse(Hamlin_Lab == 1, "yes", "no"), 
         major_author = "hamlin") 

final_trimmed_data <- pruned_data %>%  filter(ds_clean != "Prosocial Agents") %>% 
  bind_rows(pa_clean)

#write_csv(final_trimmed_data, here("data/clean_data.csv"))
```


```{r}
author_list_draft <- (final_trimmed_data %>% 
  distinct(ds_clean, long_cite) %>%
  rowwise() %>% 
  mutate(new_long_cite = sub("\\(.*", "", long_cite), 
         author_list_draft = list(strsplit(new_long_cite, ",")[[1]])))$author_list_draft

# get a list of author last name 

author_list_wo_initial <- lapply(author_list_draft, function(list_of_name){
  Filter(function(word) !grepl("\\.", word), list_of_name)
})

author_list_clean <- lapply(author_list_wo_initial, function(list_of_name){
  s <- unlist(sapply(list_of_name, function(x)gsub(" & ", "", x) %>% gsub(" ", "", .) %>% gsub("([0-9])", "", .) ), use.names = FALSE)
  
})

ds_for_author <- final_trimmed_data %>% distinct(ds_clean, long_cite)
ds_for_author$author_clean <- author_list_clean


ds_for_author <- ds_for_author %>% unnest(author_clean)


ds_author_percent <- final_trimmed_data %>% 
  left_join(ds_for_author, by = c("ds_clean", "long_cite")) %>% 
  group_by(ds_clean, author_clean) %>% 
  count() %>% 
  filter(!(author_clean %in% c("", "J", "JR", "LA", "oradvantagespeech?PLoSOne", 
                             "RL", "SD", "needmeans/sdsord", "I", 'notpresentedatconferenceandcurrentlynotat"inprep"stage', "unpublisheddataset"
                             )))%>% 
  mutate(author_clean = case_when(
    author_clean == "Byersäó\u0090Heinlein" ~ "Byers-Heinlein", 
    author_clean == "Byers‐Heinlein" ~ "Byers-Heinlein",
    author_clean == "Sebastian-Galles" ~ "Sebastián-Gallés", 
    author_clean == "Houstonäó\u0090Price" ~ "Houston-Price",
    author_clean == "Vouloumanos" ~ "Vouloumanos",
    author_clean == "andKager" ~ "Kager",
    author_clean == "andvanZuijen" ~ "vanZuijen",
    author_clean == "andWijnen" ~ "Wijnen",
    author_clean == "Lewâ€\u0090Williams" ~ "Lew-Williams",
    TRUE ~ author_clean
    
  )) %>% 
  left_join(final_trimmed_data %>% group_by(ds_clean) %>% count() %>% rename(n_effect_size = n), by = "ds_clean") %>% 
  mutate(percent_by_author = n / n_effect_size) 


clean_ds_author_percent <- ds_author_percent %>% 
  mutate(author_clean = case_when(
    ds_clean == "Language discrimination and preference" & author_clean == "Sebastián-Gallés" ~ "Sebastian-Galles",
    ds_clean == "Statistical sound category learning (habituation)" & author_clean == "vanZuijen" ~ "van Zuijen", 
    ds_clean == "Statistical sound category learning (habituation)" & author_clean == "MayeJ" ~ "Maye J",
    ds_clean == "Statistical sound category learning (habituation)" & author_clean == "WeissDJ" ~ "Weiss DJ", 
    TRUE ~ author_clean
    )
  )
  

write_csv(clean_ds_author_percent, here("data/clean_author.csv"))
```

## 8. fix stimuli naturalness

```{r}
pruned_data <- pruned_data %>% 
  mutate(
    stimuli_naturalness = case_when(
      ds_clean == "Mutual exclusivity" & object_stimulus %in% c("digital", "paper", "objects/paper") ~ "artificial", 
      ds_clean == "Mutual exclusivity" & object_stimulus %in% c("objects") ~ "natural", 
      ds_clean == "Prosocial agents" & stimuli_type %in% c("real") ~ "natural", 
      ds_clean == "Prosocial agents" & stimuli_type %in% c("cartoon") ~ "artificial", 
      ds_clean == "Label advantage in concept learning" & object_stimulus %in% c("objects") ~ "natural", 
      ds_clean == "Label advantage in concept learning" & object_stimulus %in% c("drawings") ~ "artificial", 
      ds_clean == "Abstract rule learning" & Modality %in% c("Speech")  ~ "natural", 
      ds_clean == "Abstract rule learning" & Modality %in% c("Nonspeech") ~ "artificial", 
      ds_clean == "Statistical word segmentation" & stimuli_type %in% c("natural")  ~ "natural", 
      ds_clean == "Statistical word segmentation" & stimuli_type %in% c("artificial") ~ "artificial", 
      ds_clean == "Categorization bias" & object_stimulus %in% c("picture", "word") ~ "artificial", 
      ds_clean == "Categorization bias" & object_stimulus %in% c("object") ~ "natural", 
      ds_clean == "Vowel discrimination (native)" & stimulus_naturalness %in% c("synthetic") ~ "artificial", 
      ds_clean == "Vowel discrimination (native)" & stimulus_naturalness %in% c("natural_processed", "natural") ~ "natural", 
      ds_clean == "Vowel discrimination (non-native)" & stimulus_naturalness %in% c("synthetic") ~ "artificial", 
      ds_clean == "Vowel discrimination (non-native)" & stimulus_naturalness %in% c("natural_processed", "natural") ~ "natural", 
    )
  ) 
  
```


## 9. make different versions of tidybase 

```{r}
mini_ds <- pruned_data %>% 
  select(ds_clean, long_cite,  short_cite, same_infant, study_ID, unique_row, 
         d_calc, d_var_calc, mean_age_months, response_mode, behavioral_measure, stimuli_naturalness, exposure_phase) 

write_csv(mini_ds, here("data/metalab_data_mini.csv"))
write_csv(pruned_data, here("data/metalab_data_kitchensink.csv"))

```




# basic stats 

## n of effect size 

```{r}
final_trimmed_data %>% 
  group_by(ds_clean) %>% 
  count() %>% 
  ggplot(aes(x = reorder(ds_clean, -n), y = n)) + 
  geom_point()+ 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


## n sample sizes 

```{r}
trimmed_n <- final_trimmed_data %>% 
  mutate(n_2 = ifelse(is.na(n_2), 0, n_2)) %>% 
  distinct(ds_clean, same_infant, n_1, n_2) %>% 
  mutate(total_infants = n_1 + n_2) %>% 
  group_by(ds_clean) %>% 
  summarise(n = sum(total_infants)) %>% 
  arrange(n) 

trimmed_n %>% 
  ggplot(aes(reorder(ds_clean,-n), n)) + 
  geom_point() + 
  theme_classic() + 
  theme() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

do we worry about the potential outliers here? ds that has small effect size n but contributes a lot of sample n? 

```{r}
final_trimmed_data %>% 
  group_by(ds_clean) %>% 
  count() %>% 
  rename(effect_size_n = n) %>% 
  left_join(trimmed_n %>% rename(sample_size = n), by = "ds_clean") %>% 
  ggplot(aes(x = effect_size_n, 
             y = sample_size)) + 
  geom_point() + 
  geom_smooth(method = "lm")

```


## method distribution 


### response mode 

```{r}
final_trimmed_data %>% 
  group_by(ds_clean, response_mode) %>% 
  count() %>% 
  ungroup() %>% 
  left_join(
    final_trimmed_data %>% 
  group_by(ds_clean) %>% summarise(n_row = n()), 
  by = "ds_clean"
  ) %>% 
  mutate(proportion_response_mode = n/ n_row) %>% 
  
  ggplot(aes(x = reorder(response_mode, -proportion_response_mode), y = proportion_response_mode)) + 
  geom_point() + 
  facet_wrap(~ds_clean) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), 
        strip.text.x = element_text(size = 7)) + 
  labs(title = "Response mode")
```

### method

```{r}
final_trimmed_data %>% 
  group_by(ds_clean, method) %>% 
  count() %>% 
  ungroup() %>% 
  left_join(
    final_trimmed_data %>% 
  group_by(ds_clean) %>% summarise(n_row = n()), 
  by = "ds_clean"
  ) %>% 
  mutate(proportion_method = n/ n_row) %>% 
  
  ggplot(aes(x = reorder(method, -proportion_method), y = proportion_method)) + 
  geom_point() + 
  facet_wrap(~ds_clean) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), 
        strip.text.x = element_text(size = 7)) + 
  labs(title = "method")
```


### dependent_measure 

```{r}
final_trimmed_data %>% 
  group_by(ds_clean, dependent_measure) %>% 
  count() %>% 
  ungroup() %>% 
  left_join(
    final_trimmed_data %>% 
  group_by(ds_clean) %>% summarise(n_row = n()), 
  by = "ds_clean"
  ) %>% 
  mutate(proportion_dm = n/ n_row) %>% 
  ggplot(aes(x = dependent_measure, y = proportion_dm)) + 
  geom_point() + 
  facet_wrap(~ds_clean) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), 
        strip.text.x = element_text(size = 7)) + 
  labs(title = "dependent_measure")
```


### coded: looking 

```{r}
filter(final_trimmed_data, 
       mean_age_months < 36) %>%
  ggplot(aes(x = mean_age_months, y = d_calc, 
             weight = 1/d_var_calc)) +
  geom_point(aes(size = 1/d_var_calc,  
             color = looking),
             alpha = .3) + 
  facet_wrap(~ ds_clean) + 
  geom_hline(yintercept = 0, lty = 2, col = "black") + 
  xlab("Mean age (months)") +
  ylab("Effect size (d)") +
  ggthemes::theme_few()
```

### coded: behavioral_measure

```{r}
filter(final_trimmed_data, 
       mean_age_months < 36) %>%
  ggplot(aes(x = mean_age_months, y = d_calc, 
             weight = 1/d_var_calc)) +
  geom_point(aes(size = 1/d_var_calc,  
             color = behavioral_measure),
             alpha = .3) + 
  facet_wrap(~ ds_clean) + 
  geom_hline(yintercept = 0, lty = 2, col = "black") + 
  xlab("Mean age (months)") +
  ylab("Effect size (d)") +
  ggthemes::theme_few()

filter(final_trimmed_data, 
       mean_age_months < 36) %>%
  ggplot(aes(x = mean_age_months, y = d_calc, 
             weight = 1/d_var_calc)) +
  geom_point(aes(size = 1/d_var_calc,  
             color = behavioral_measure),
             alpha = .3 
            ) + 
  geom_hline(yintercept = 0, lty = 2, col = "black") + 
  xlab("Mean age (months)") +
  ylab("Effect size (d)") +
  ggthemes::theme_few()
```


### fam vs hab vs test only 

```{r}
filter(final_trimmed_data, 
       mean_age_months < 36)  %>% 
  filter(exposure_phase %in% c("familiarization", "habituation", "test_only"), 
         looking == "yes") %>% 
  ggplot(aes(x = mean_age_months, y = d_calc, 
             weight = 1/d_var_calc)) +
  geom_point(aes(size = 1/d_var_calc,  
             color = exposure_phase),
             alpha = .3) + 
  facet_wrap( ~ ds_clean) + 
  geom_hline(yintercept = 0, lty = 2, col = "black") + 
  xlab("Mean age (months)") +
  ylab("Effect size (d)") +
  ggthemes::theme_few()
```





## publicaion year

citation density?


```{r}
final_trimmed_data  %>% 
  ggplot(aes(x = year, y = d_calc, color = publication_type)) +
  geom_point() + 
  facet_wrap( ~ ds_clean) + 
  geom_hline(yintercept = 0, lty = 2, col = "black") + 
  xlab("publishing year") +
  ylab("Effect size (d)") +
  ggthemes::theme_few() 
```
